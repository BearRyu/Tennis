# CapStone Design2 

## Path prediction during a tennis match

### Index

#### Data Introduction

#### Code

#### Specific code description

ğŸ—‚ï¸ Data

* ë°ì´í„°ëŠ” ìµœê·¼ ì˜¬ë¦¼í”½ ê²½ê¸°ì˜€ë˜ í…Œë‹ˆìŠ¤ ë‚¨ìë‹¨ì‹ 2íšŒì „ ë…¸ë°• ì¡°ì½”ë¹„ì¹˜ vs ë¼íŒŒì—˜ ë‚˜ë‹¬ì˜ ê²½ê¸° ì¤‘ ì¼ë¶€ë¶„ì„ ë”°ì™”ìŠµë‹ˆë‹¤!

[2024 íŒŒë¦¬ ì˜¬ë¦¼í”½ í…Œë‹ˆìŠ¤ ë‚¨ìë‹¨ì‹](https://www.youtube.com/watch?v=8Mlg7s6gW-M)

ğŸ¾ ì´ ê²½ê¸° ì¤‘ 13:29 ~ 13:54 ê²½ê¸°ë¥¼ ê°€ì§€ê³  ì™”ìŠµë‹ˆë‹¤!

[ì›ë³¸ ë™ì˜ìƒ](https://drive.google.com/file/d/1Mne0YNvXHv1DAu-Oi0CeqnkVZu-EL2RZ/view?usp=drive_link)

ğŸ’» Code

# 1. í”„ë ˆì„ ë‚˜ëˆ„ê¸° 

import cv2
import os

# ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
video_path = r'D:/Tennis_Video/Tennis_MP4_5.mp4'
output_folder = r'D:/Tennis_Video/Frames'

# í”„ë ˆì„ì„ ì €ì¥í•  í´ë” ìƒì„±
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
cap = cv2.VideoCapture(video_path)

frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # ê° í”„ë ˆì„ì„ JPG íŒŒì¼ë¡œ ì €ì¥
    frame_filename = os.path.join(output_folder, f'frame_{frame_count:04d}.jpg')
    cv2.imwrite(frame_filename, frame)
    
    frame_count += 1

cap.release()
print(f"Total frames saved: {frame_count}")


# 2. ê°ì²´ íƒì§€

 '''python
import cv2  
import os  

video_path = 'D:/Tennis_Video/Tennis_MP4_5.mp4'  
output_video_path = 'D:/Tennis_Video/Tennis_Output_with_Frame_Label.mp4'  
frame_label_dir = 'D:/Tennis_Video/frame_label'  

class_mapping = {0: "ball", 1: "player", 2: "tennis racket", 3: "referee"}  
class_colors = {  
    0: (255, 0, 0),     
    1: (0, 255, 0),   
    2: (0, 0, 255),   
    3: (255, 255, 0)    
}

cap = cv2.VideoCapture(video_path)  
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  
fps = int(cap.get(cv2.CAP_PROP_FPS))  
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))  

frame_index = 0  

while cap.isOpened():  
    ret, frame = cap.read()  
    if not ret:  
        break  

    label_file = os.path.join(frame_label_dir, f'frame_{frame_index:04d}.txt')  

    if os.path.exists(label_file):  
        # Read the label file  
        with open(label_file, 'r') as f:  
            lines = f.readlines()  

        for line in lines:  
            values = line.strip().split()  
            class_id = int(values[0])  
            x_center, y_center = float(values[1]) * width, float(values[2]) * height  
            box_width, box_height = float(values[3]) * width, float(values[4]) * height  
  
            x1 = int(x_center - box_width / 2)  
            y1 = int(y_center - box_height / 2)  
            x2 = int(x_center + box_width / 2)  
            y2 = int(y_center + box_height / 2)  

            color = class_colors.get(class_id, (255, 255, 255))      
            label = class_mapping.get(class_id, "Unknown")  
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)  
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)  

    out.write(frame)  
    frame_index += 1  

cap.release()	
out.release()	
cv2.destroyAllWindows()	
print("Video processing with frame labels completed.")	
'''

* ì´ ì½”ë“œëŠ” ê°ì²´ë¥¼ íƒì§€í•˜ê³  ì˜ìƒì—ì„œ ê·¸ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ìˆìŒì„ ë³´ì—¬ì£¼ê³  ìˆëŠ” ì½”ë“œ ì…ë‹ˆë‹¤.

1. ê²½ë¡œ ë° í´ë˜ìŠ¤ ë§¤í•‘ ì •ì˜: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ, ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ, í”„ë ˆì„ ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì„¤ì •í•˜ê³ . ë˜í•œ, í´ë˜ìŠ¤ IDì™€ í•´ë‹¹ í´ë˜ìŠ¤ ì´ë¦„ ë° ìƒ‰ìƒì— ë”°ë¼ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

2. ë¹„ë””ì˜¤ ìº¡ì²˜ ë° ì‘ì„±ê¸° ì„¤ì •: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì½ê¸° ìœ„í•´ OpenCVì˜ VideoCapture ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , ë¹„ë””ì˜¤ì˜ ë„ˆë¹„, ë†’ì´, í”„ë ˆì„ ì†ë„ë¥¼ ê°€ì ¸ì˜¤ê³  ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.

3. í”„ë ˆì„ ì²˜ë¦¬: ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—´ë ¤ ìˆëŠ” ë™ì•ˆ ê° í”„ë ˆì„ì„ ì½ì–´ì™€, ê° í”„ë ˆì„ì— ëŒ€í•´ í•´ë‹¹ í”„ë ˆì„ì˜ ë¼ë²¨ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì¡´ì¬í•˜ë©´ ë¼ë²¨ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤. ë¼ë²¨ íŒŒì¼ì—ëŠ” ê°ì²´ì˜ í´ë˜ìŠ¤ IDì™€ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

4. ë°”ìš´ë”© ë°•ìŠ¤ ë° ë¼ë²¨ ê·¸ë¦¬ê¸°: ê° ê°ì²´ì— ëŒ€í•´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê³„ì‚°í•˜ê³ , í•´ë‹¹ í´ë˜ìŠ¤ì˜ ìƒ‰ìƒê³¼ ë¼ë²¨ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ì— ê·¸ë¦½ë‹ˆë‹¤.

5. ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ì— í”„ë ˆì„ ì“°ê¸°: ì²˜ë¦¬ëœ ê° í”„ë ˆì„ì„ ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ì— ì”ë‹ˆë‹¤.

6. ì‹¤í–‰ ì¢…ë£Œ: ë¹„ë””ì˜¤ ìº¡ì²˜ ë° ì‘ì„±ê¸° ê°ì²´ë¥¼ í•´ì œí•˜ê³ , ëª¨ë“  OpenCV ì°½ì„ ë‹«ìŠµë‹ˆë‹¤.


# 3. ê²½ë¡œ ì˜ˆì¸¡ í™”ì‚´í‘œ ì½”ë“œ

'''python
import cv2	
import os	

video_path = 'D:/Tennis_Video/Tennis_MP4_5.mp4'	
output_video_path = 'D:/Tennis_Video/Predict_path_Tennis.mp4'	
frame_label_dir = 'D:/Tennis_Video/frame_label'	

class_mapping = {0: "ball", 1: "player", 2: "tennis racket", 3: "referee"}	
class_colors = {	
    0: (255, 0, 0),	    	
    1: (0, 255, 0), 	   
    2: (0, 0, 255),    
    3: (255, 255, 0)	   
}

opponent_court_bounds = [(733, 374), (1221, 372), (692, 483), (1266, 487)]	

def calculate_distance(point1, point2):	
    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5	

def find_optimal_targets(opponent_player, court_bounds):	
    distances = [(calculate_distance(opponent_player, corner), corner) for corner in court_bounds]	
    distances.sort(reverse=True, key=lambda x: x[0])	
    return [corner for _, corner in distances[:3]]	

def bounding_boxes_overlap(box1, box2):	
    """Check if two bounding boxes overlap."""	
    x1_min, y1_min, x1_max, y1_max = box1	
    x2_min, y2_min, x2_max, y2_max = box2	
    return not (x1_max < x2_min or x2_max < x1_min or y1_max < y2_min or y2_max < y1_min)	

def draw_arrows(frame, ball_position, targets):	
    for target in targets:	
        pt1 = (int(ball_position[0]), int(ball_position[1]))	
        pt2 = (int(target[0]), int(target[1]))	
        cv2.arrowedLine(frame, pt1, pt2, (0, 0, 255), 2, tipLength=0.2)  		
        cv2.circle(frame, pt2, 5, (0, 0, 255), -1) 	

cap = cv2.VideoCapture(video_path)	
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))	
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))	
fps = int(cap.get(cv2.CAP_PROP_FPS))	
fourcc = cv2.VideoWriter_fourcc(*'mp4v')	
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))	

frame_index = 0	
	
while cap.isOpened():	
    ret, frame = cap.read()		
    if not ret:	
        break	

    label_file = os.path.join(frame_label_dir, f'frame_{frame_index:04d}.txt')	

    ball_position = None	
    racket_position = None	
    players = []	

    if os.path.exists(label_file):	
        
        with open(label_file, 'r') as f:	
            lines = f.readlines()	

        for line in lines:	
            values = line.strip().split()	
            class_id = int(values[0])	
            x_center, y_center = float(values[1]) * width, float(values[2]) * height	
            box_width, box_height = float(values[3]) * width, float(values[4]) * height	

            x1 = int(x_center - box_width / 2)	
            y1 = int(y_center - box_height / 2)	
            x2 = int(x_center + box_width / 2)	
            y2 = int(y_center + box_height / 2)	

            if class_id == 0:  	
                ball_position = (x_center, y_center)	
                ball_box = (x1, y1, x2, y2)	
            elif class_id == 2:  	
                racket_position = (x_center, y_center)	
                racket_box = (x1, y1, x2, y2)		
            elif class_id == 1:  		
                players.append((x_center, y_center))		

            color = class_colors.get(class_id, (255, 255, 255))  		
            label = class_mapping.get(class_id, "Unknown")	
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)		
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)	

    if ball_position and racket_position and bounding_boxes_overlap(ball_box, racket_box):	
        	
        if players:
            opponent_player = max(players, key=lambda p: calculate_distance(racket_position, p))	
            
            targets = find_optimal_targets(opponent_player, opponent_court_bounds)	
            
            draw_arrows(frame, ball_position, targets)

    out.write(frame)
    frame_index += 1

cap.release()	
out.release()	
cv2.destroyAllWindows()	
print("Video processing with predictions completed.")	
'''

[ê²°ê³¼ ë™ì˜ìƒ] (https://drive.google.com/file/d/17_ZVFfSGgqqQTYXNizgPydWuuO-o9km_/view?usp=sharing)

* ì´ ì½”ë“œì˜ ê¸°ëŠ¥ì„ ì•Œë ¤ë“œë¦¬ìë©´,

1. ê°ì²´ íƒì§€ ë° ì£¼ì„ í‘œì‹œ
- ê° í”„ë ˆì„ì—ì„œ ê³µ, ì„ ìˆ˜, í…Œë‹ˆìŠ¤ ë¼ì¼“, ì‹¬íŒ ë“±ì˜ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ì£¼ì„ì„ í‘œì‹œí•©ë‹ˆë‹¤.
- ê°ì²´ë¥¼ ì‰½ê²Œ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ê²Œ í•©ë‹ˆë‹¤.

- ê³µ: íŒŒë€ìƒ‰ , ì„ ìˆ˜: ì´ˆë¡ìƒ‰, ë¼ì¼“: ë¹¨ê°„ìƒ‰, ì‹¬íŒ: ë…¸ë€ìƒ‰

2. ê³µ ê¶¤ì  ì˜ˆì¸¡

- ê³µê³¼ ë¼ì¼“ì´ ê²¹ì¹˜ëŠ” ê²½ìš°(íƒ€ê²©ì´ ì´ë£¨ì–´ì§ˆ ê°€ëŠ¥ì„±)ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
- ìƒëŒ€ ì„ ìˆ˜ì˜ ìœ„ì¹˜ì™€ ì½”íŠ¸ ëª¨ì–‘ì„ ê¸°ë°˜ìœ¼ë¡œ ê³µì˜ ë¯¸ë˜ ê¶¤ì ì„ ì˜ˆì¸¡í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.

3. ë™ì  ì‹œê°í™”

- ì˜ˆì¸¡ëœ ê³µì˜ ê¶¤ì ì„ í™”ì‚´í‘œë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
- ëª©í‘œ ì§€ì ì„ ì‘ì€ ë¹¨ê°„ìƒ‰ ì›ìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ëª…í™•ì„±ì„ ë†’ì…ë‹ˆë‹¤.


# 4. YOLO ëª¨ë¸ í™œìš©

import cv2	
import os	
from ultralytics import YOLO	


video_path = 'D:/Tennis_Video/Tennis_MP4_5.mp4'	
output_video_path = 'D:/Tennis_Video/Predict_path_Tennis.mp4'	
	

class_mapping = {0: "ball", 1: "player", 2: "tennis racket", 3: "referee"}	
class_colors = {
    "ball": (255, 0, 0),   	
    "player": (0, 255, 0),	
    "tennis racket": (0, 0, 255),  	
    "referee": (255, 255, 0) 	
}


opponent_court_bounds = [(733, 374), (1221, 372), (692, 483), (1266, 487)]	

model = YOLO('yolov8n.pt') 	
def calculate_distance(point1, point2):	
    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5	

def find_optimal_targets(opponent_player, court_bounds):	
    distances = [(calculate_distance(opponent_player, corner), corner) for corner in court_bounds]	
    distances.sort(reverse=True, key=lambda x: x[0])	
    return [corner for _, corner in distances[:3]]	

def draw_arrows(frame, ball_position, targets):	
    for target in targets:	
        pt1 = (int(ball_position[0]), int(ball_position[1]))	
        pt2 = (int(target[0]), int(target[1]))	
        cv2.arrowedLine(frame, pt1, pt2, (0, 0, 255), 2, tipLength=0.2)  	
        cv2.circle(frame, pt2, 5, (0, 0, 255), -1)	  

	
cap = cv2.VideoCapture(video_path)	
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))		
fps = int(cap.get(cv2.CAP_PROP_FPS))	
fourcc = cv2.VideoWriter_fourcc(*'mp4v')	
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))	

frame_index = 0	

while cap.isOpened():	
    ret, frame = cap.read()
    if not ret:	
        break	


    results = model.predict(frame, save=False, conf=0.5)  	
    detections = results[0].boxes.data.cpu().numpy() 	
	
    ball_position = None	
    racket_position = None	
    players = []	

    for detection in detections:
        x1, y1, x2, y2, confidence, class_id = detection	
        class_name = class_mapping.get(int(class_id), "Unknown")	
	
        x_center = (x1 + x2) / 2		
        y_center = (y1 + y2) / 2	
        box_width = x2 - x1		
        box_height = y2 - y1	

       
        color = class_colors.get(class_name, (255, 255, 255))	
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)	
        cv2.putText(frame, class_name, (int(x1), int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)	


        if class_name == "ball":	
            ball_position = (x_center, y_center)	
            ball_box = (x1, y1, x2, y2)	
        elif class_name == "tennis racket":	
            racket_position = (x_center, y_center)	
            racket_box = (x1, y1, x2, y2)	
        elif class_name == "player":	
            players.append((x_center, y_center))	

   
    if ball_position and racket_position and bounding_boxes_overlap(ball_box, racket_box):	
        if players:	
            opponent_player = max(players, key=lambda p: calculate_distance(racket_position, p))	
           
            targets = find_optimal_targets(opponent_player, opponent_court_bounds)	
            
            draw_arrows(frame, ball_position, targets)	

   
    out.write(frame)	
    frame_index += 1		

cap.release()	
out.release()	
print("Video processing with YOLOv8 predictions completed.")	

#### 1. ì´ˆê¸° ì„¤ì •
- ë¹„ë””ì˜¤ ì…ë ¥ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •
	- video_path: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ.
	- output_video_path: ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ.
 
- í´ë˜ìŠ¤ ë§¤í•‘ ë° ìƒ‰ìƒ ì„¤ì •
	- class_mapping: YOLOv8 ëª¨ë¸ì´ ë°˜í™˜í•˜ëŠ” í´ë˜ìŠ¤ IDë¥¼ ì½ê¸° ì‰¬ìš´ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘.
	- class_colors: íƒì§€ëœ ê°ì²´ë¥¼ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•˜ê¸° ìœ„í•œ RGB ê°’ ì„¤ì •.
   
- ìƒëŒ€ ì½”íŠ¸ ì¢Œí‘œ ì„¤ì •
	- opponent_court_bounds: ìƒëŒ€ ì½”íŠ¸ì˜ 4ê°œ ê¼­ì§“ì  ì¢Œí‘œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
	- ì´ë¥¼ ì´ìš©í•´ ê³µì˜ ê¶¤ì ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

- YOLOv8 ëª¨ë¸ ë¡œë“œ
	- YOLO('yolov8n.pt'): ì‚¬ì „ í•™ìŠµëœ YOLOv8n ëª¨ë¸ ë¡œë“œ.

#### 2. ë³´ì¡° í•¨ìˆ˜
- ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜: calculate_distance
	 - ë‘ ì  ê°„ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
	 - ê³µê³¼ ì½”íŠ¸, ìƒëŒ€ ì„ ìˆ˜ ê°„ì˜ ê±°ë¦¬ ë¹„êµì— ì‚¬ìš©ë©ë‹ˆë‹¤.

- ëª©í‘œ ìœ„ì¹˜ ê³„ì‚° í•¨ìˆ˜: find_optimal_targets
	- ê³µì„ ì¹œ ì„ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì½”íŠ¸ ê¼­ì§“ì ì—ì„œ ë¨¼ ì„¸ ê³³ì„ ì„ íƒí•´ ê³µì˜ ê¶¤ì ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

- í™”ì‚´í‘œ ê·¸ë¦¬ê¸° í•¨ìˆ˜: draw_arrows
	- ì˜ˆì¸¡ëœ ëª©í‘œ ìœ„ì¹˜ë¡œ í–¥í•˜ëŠ” í™”ì‚´í‘œë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
	- í™”ì‚´í‘œì˜ ëì ì— ì‘ì€ ì›ì„ í‘œì‹œí•˜ì—¬ ëª…í™•ì„±ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

#### 3. ë¹„ë””ì˜¤ ì²˜ë¦¬
- ë¹„ë””ì˜¤ ìº¡ì²˜ ë° ì¶œë ¥ ì„¤ì •
  - OpenCVë¥¼ ì´ìš©í•´ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì½ê³  ë¶„ì„ëœ ê²°ê³¼ë¥¼ ìƒˆ ë¹„ë””ì˜¤ë¡œ ì €ì¥.

- í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
	- while cap.isOpened(): ë¹„ë””ì˜¤ì˜ ê° í”„ë ˆì„ì„ ë°˜ë³µì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

- YOLOv8 ëª¨ë¸ì„ ì´ìš©í•œ ê°ì²´ íƒì§€
	- model.predict(frame, save=False, conf=0.5): YOLOv8 ëª¨ë¸ë¡œ í˜„ì¬ í”„ë ˆì„ì˜ ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
	- results[0].boxes.data: íƒì§€ ê²°ê³¼ë¡œë¶€í„° ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ, ì‹ ë¢°ë„, í´ë˜ìŠ¤ ID ì¶”ì¶œ.

#### 4. íƒì§€ëœ ê°ì²´ ì²˜ë¦¬
- ê°ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ë° ë ˆì´ë¸” í‘œì‹œ
	- í´ë˜ìŠ¤ ì´ë¦„ê³¼ ìƒ‰ìƒì„ ì‚¬ìš©í•´ ê° ê°ì²´ë¥¼ ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.

- íŠ¹ì • ê°ì²´ ìœ„ì¹˜ ì €ì¥
	- ball_position: ê³µì˜ ì¤‘ì‹¬ ì¢Œí‘œ.
	- racket_position: í…Œë‹ˆìŠ¤ ë¼ì¼“ì˜ ì¤‘ì‹¬ ì¢Œí‘œ.
	- players: íƒì§€ëœ ëª¨ë“  ì„ ìˆ˜ì˜ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸.

#### 5. ê³µ ê¶¤ì  ì˜ˆì¸¡ ë° ì‹œê°í™”
- ê³µê³¼ ë¼ì¼“ì˜ ê²¹ì¹¨ ì—¬ë¶€ í™•ì¸
	- ê³µê³¼ ë¼ì¼“ì˜ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê²¹ì¹˜ë©´ ê³µì´ íƒ€ê²©ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼.

- ìƒëŒ€ ì„ ìˆ˜ì™€ ì½”íŠ¸ ì¢Œí‘œ ê¸°ë°˜ ê¶¤ì  ì˜ˆì¸¡
	- ìƒëŒ€ ì„ ìˆ˜ê°€ ì½”íŠ¸ì—ì„œ ê°€ì¥ ë¨¼ 3ê³³ì„ ëª©í‘œ ì§€ì ìœ¼ë¡œ ì„¤ì •.

- í™”ì‚´í‘œë¡œ ê¶¤ì  ì‹œê°í™”
	- ê³µì˜ í˜„ì¬ ìœ„ì¹˜ì—ì„œ ëª©í‘œ ì§€ì ê¹Œì§€ì˜ ê²½ë¡œë¥¼ í™”ì‚´í‘œë¡œ í‘œì‹œ.
	- ëª©í‘œ ì§€ì ì€ ì‘ì€ ì›ìœ¼ë¡œ ê°•ì¡° í‘œì‹œ.

[ê²°ê³¼ ë™ì˜ìƒ] (https://drive.google.com/file/d/1NsFtVnyn81ACvfg3Y6bv1boIqsHk3Gc-/view?usp=drive_link)

### ë¹„êµì  ë° í•œê³„ì 

ë¼ë²¨ë§ì„ í†µí•´ ì½”ë”©ì„ í•˜ê³  ìƒëŒ€ ì„ ìˆ˜ì™€ì˜ ë¨¼ ë°©í–¥ìœ¼ë¡œ 1ê°œ ê°€ê¹Œìš´ ìª½ìœ¼ë¡œ 2ê°œë¥¼ í™”ì‚´í‘œë¥¼ ê¸‹ëŠ” ì˜ˆìƒ ê²½ë¡œëŠ” ì˜ ë‚˜ì™”ìœ¼ë‚˜,  
YOLOv8n ëª¨ë¸ ë¬¼ë¡  ì‚¬ëŒì— ëŒ€í•œ íƒì§€ëŠ” ì˜ í–ˆìœ¼ë‚˜, ê³µì˜ í°ìƒ‰ì´ í…Œë‹ˆìŠ¤ ê²½ê¸°ì¥ ë¼ì¸ ìƒ‰ê¹”ê³¼ ë¹„ìŠ·í•˜ì—¬ íƒì§€ë¥¼ í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ì§„í–‰ í•˜ë”ë¼ë„ ë¼ë²¨ë§ì˜ í•„ìš”ì„±ì„ ì•Œê²Œ ë˜ì—ˆê³ , ì§§ì€ ì˜ìƒ í•˜ë‚˜ë¡œ ë‹¤ë£¨ê²Œ ë˜ì–´ ë‹¤ì–‘í•œ ê²½ê¸°ë“¤ì„ ë¶„ì„í•˜ê±°ë‚˜, ê° ì„ ìˆ˜ë“¤ì˜ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•˜ì˜€ë‹¤ëŠ” ì ì´ ì•„ì‰¬ìš´ ì ìœ¼ë¡œ ìƒê°í•©ë‹ˆë‹¤.

### ğŸ¤ ê¸°ëŒ€íš¨ê³¼

#### 1. ìŠ¤í¬ì¸  ë¶„ì„ ì‹œìŠ¤í…œ ê°œë°œ.
#### 2. í…Œë‹ˆìŠ¤ ê²½ê¸° ë°ì´í„° ì‹œê°í™” ë° ì „ëµ ë¶„ì„.
#### 3. AI ê¸°ë°˜ ìŠ¤í¬ì¸  íŠ¸ë˜í‚¹ ë° ë¦¬í”Œë ˆì´ ì œì‘.

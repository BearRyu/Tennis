{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py38_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\n",
      "\u001b[2K\n",
      "Ultralytics 8.3.29 🚀 Python-3.10.2 torch-2.1.2+cpu CPU (Intel Core(TM) i3-8145U 2.10GHz)\n",
      "Setup complete ✅ (4 CPUs, 7.9 GB RAM, 367.0/1816.4 GB disk)\n",
      "\n",
      "OS                  Windows-10-10.0.19045-SP0\n",
      "Environment         Windows\n",
      "Python              3.10.2\n",
      "Install             pip\n",
      "RAM                 7.90 GB\n",
      "Disk                367.0/1816.4 GB\n",
      "CPU                 Intel Core(TM) i3-8145U 2.10GHz\n",
      "CPU count           4\n",
      "GPU                 None\n",
      "GPU count           None\n",
      "CUDA                None\n",
      "\n",
      "numpy               ✅ 1.26.1>=1.23.0\n",
      "matplotlib          ✅ 3.8.1>=3.3.0\n",
      "opencv-python       ✅ 4.9.0.80>=4.6.0\n",
      "pillow              ✅ 10.1.0>=7.1.2\n",
      "pyyaml              ✅ 6.0.1>=5.3.1\n",
      "requests            ✅ 2.31.0>=2.23.0\n",
      "scipy               ✅ 1.13.0>=1.4.1\n",
      "torch               ✅ 2.1.2>=1.8.0\n",
      "torchvision         ✅ 0.16.2>=0.9.0\n",
      "tqdm                ✅ 4.66.1>=4.64.0\n",
      "psutil              ✅ 5.9.5\n",
      "py-cpuinfo          ✅ 9.0.0\n",
      "pandas              ✅ 2.1.1>=1.1.4\n",
      "seaborn             ✅ 0.13.2>=0.11.0\n",
      "ultralytics-thop    ✅ 2.0.0>=2.0.0\n",
      "numpy               ✅ 1.26.1<2.0.0; sys_platform == \"darwin\"\n",
      "torch               ✅ 2.1.2!=2.4.0,>=1.8.0; sys_platform == \"win32\"\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking(model, video, plot_bbox=False, save=False, save_as='output.avi', mot16=False):\n",
    "    \"\"\"\n",
    "    입력 비디오 경로의 영상으로부터 YOLO 검출 모델 기반 트래킹을 수행함. 각 프레임이 처리될 때마다 처리결과를 display window에서 보여줌.\n",
    "    처리결과(영상 또는 MOT16 annotation)를 저장할 수 있음\n",
    "    \n",
    "        : model (string): YOLOv8n 가중치 파일 경로. 반드시 YOLOv8n에 상응하는 가중치를 사용해야함\n",
    "        : video (string): 검출 및 트래킹을 수행할 입력 비디오 경로\n",
    "        : plot_bbox (bool): 처리결과에 bounding box를 시각화할 것인지\n",
    "        : save (bool): 트래킹 결과 영상을 저장할 것인지\n",
    "        : save_as (string): (save=True일 때) 트래킹 결과 영상을 저장할 경로. 반드시 .avi 확장자여야 함\n",
    "        : mot16 (bool): 트래킹 결과 MOT16 format annotation 텍스트 파일(.txt)을 현재 디렉토리에 저장할 것인지 (mot16_tracking_results.txt)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    model = YOLO(weight)\n",
    "    \n",
    "    # Open the video file\n",
    "    video_path = video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Video Write IF 'save' IS TRUE\n",
    "    if save:\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        out = cv2.VideoWriter(save_as, fourcc, fps, (width, height))\n",
    "        \n",
    "    # Generate MOT-16 format output file IF 'mot16' IS TRUE\n",
    "    if mot16:\n",
    "        mot16_file_path = 'mot16_tracking_results.txt'\n",
    "        mot16_file = open(output_file_path, 'w')\n",
    "        \n",
    "    # Store the track history\n",
    "    track_history = defaultdict(lambda: [])\n",
    "    \n",
    "    # Init frame number for writing MOT-16 format annotation file\n",
    "    fnum = 1\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(frame, persist=True, tracker='bytetrack.yaml')\n",
    "        \n",
    "            # Get the boxes and track IDs\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "            confs = results[0].boxes.conf\n",
    "            clss = results[0].boxes.cls\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            # https://docs.ultralytics.com/reference/engine/results/#ultralytics.engine.results.Results.numpy\n",
    "            annotated_frame = results[0].plot(boxes=plot_bbox)\n",
    "        \n",
    "            # Write MOT-16 format annotation file\n",
    "            if mot16:\n",
    "                expansion_factor = 3 # expansion_factor defined in 'update' method of BYTETracker class (byte_tracker.py)\n",
    "                \n",
    "                for box, track_id, conf, cls in zip(boxes, track_ids, confs, clss):\n",
    "                    x, y, w, h = box\n",
    "                    if cls == 1:\n",
    "                        w, h = (w / expansion_factor), (h / expansion_factor)\n",
    "                    x, y, w, h = x - (w / 2), y - (h / 2), w, h\n",
    "                    mot16_file.write(f\"{fnum},{track_id},{x},{y},{w},{h},{conf},{int(cls)},-1,-1\\n\")\n",
    "            \n",
    "            # Plot the tracks\n",
    "            for box, track_id, cls in zip(boxes, track_ids, clss):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "            \n",
    "                # Plot the tracks of players\n",
    "                if cls == 0:\n",
    "                    track.append((float(x), float(y + 0.4*h)))  # points of players' foot\n",
    "                    if len(track) > 50:  # retain 50 tracks for 50 frames\n",
    "                        track.pop(0)\n",
    "                    for i, (x_, y_) in enumerate(track):\n",
    "                        cv2.ellipse(annotated_frame, center=(int(x_), int(y_)), axes=(int(0.1*w), int(0.05*w)), \n",
    "                                    angle=0, startAngle=0, endAngle=360, color=(255 - 2*i, 200 - 5*i, 0), thickness=int(i/5))\n",
    "\n",
    "                # Plot the tracks of tennis ball\n",
    "                else: # elif cls == 1:\n",
    "                    track.append((float(x), float(y)))  # x, y center(ball) point\n",
    "                    if len(track) > 20:  # retain 20 tracks for 20 frames\n",
    "                        track.pop(0)\n",
    "                \n",
    "                    for i, (x_, y_) in enumerate(track):\n",
    "                        cv2.circle(annotated_frame, center=(int(x_), int(y_)), radius=int(i/3),\n",
    "                                    color=(255 - 10*i, 250, 250), thickness=2)\n",
    "        \n",
    "            # Video Write\n",
    "            if save:\n",
    "                out.write(annotated_frame)\n",
    "            \n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "\n",
    "            fnum += 1\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Release the video writer\n",
    "    if save:\n",
    "        out.release()\n",
    "    \n",
    "    # Close writing the MOT-16 output file\n",
    "    if mot16:\n",
    "        mot16_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 트레킹 완료본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to video and frame_label directory\n",
    "video_path = 'D:/Tennis_Video/Tennis_MP4_5.mp4'\n",
    "output_video_path = 'D:/Tennis_Video/Tennis_Output_with_Frame_Label.mp4'\n",
    "frame_label_dir = 'D:/Tennis_Video/frame_label'\n",
    "\n",
    "# Class mapping\n",
    "class_mapping = {0: \"ball\", 1: \"player\", 2: \"tennis racket\", 3: \"referee\"}\n",
    "class_colors = {\n",
    "    0: (255, 0, 0),    # Blue for ball\n",
    "    1: (0, 255, 0),    # Green for player\n",
    "    2: (0, 0, 255),    # Red for tennis racket\n",
    "    3: (255, 255, 0)   # Yellow for referee\n",
    "}\n",
    "\n",
    "# Video capture and writer setup\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_index = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Path to corresponding frame label file\n",
    "    label_file = os.path.join(frame_label_dir, f'frame_{frame_index:04d}.txt')\n",
    "\n",
    "    if os.path.exists(label_file):\n",
    "        # Read the label file\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            values = line.strip().split()\n",
    "            class_id = int(values[0])\n",
    "            x_center, y_center = float(values[1]) * width, float(values[2]) * height\n",
    "            box_width, box_height = float(values[3]) * width, float(values[4]) * height\n",
    "\n",
    "            # Calculate bounding box coordinates\n",
    "            x1 = int(x_center - box_width / 2)\n",
    "            y1 = int(y_center - box_height / 2)\n",
    "            x2 = int(x_center + box_width / 2)\n",
    "            y2 = int(y_center + box_height / 2)\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            color = class_colors.get(class_id, (255, 255, 255))  # Default to white if class_id is unknown\n",
    "            label = class_mapping.get(class_id, \"Unknown\")\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    # Write the frame to output video\n",
    "    out.write(frame)\n",
    "    frame_index += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video processing with frame labels completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 화살표 경로 예측 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to video and frame_label directory\n",
    "video_path = 'D:/Tennis_Video/Tennis_MP4_5.mp4'\n",
    "output_video_path = 'D:/Tennis_Video/Predict_path_Tennis.mp4'\n",
    "frame_label_dir = 'D:/Tennis_Video/frame_label'\n",
    "\n",
    "# Class mapping and colors\n",
    "class_mapping = {0: \"ball\", 1: \"player\", 2: \"tennis racket\", 3: \"referee\"}\n",
    "class_colors = {\n",
    "    0: (255, 0, 0),    # Blue for ball\n",
    "    1: (0, 255, 0),    # Green for player\n",
    "    2: (0, 0, 255),    # Red for tennis racket\n",
    "    3: (255, 255, 0)   # Yellow for referee\n",
    "}\n",
    "\n",
    "# Define opponent court bounds (top-left, top-right, bottom-left, bottom-right)\n",
    "opponent_court_bounds = [(733, 374), (1221, 372), (692, 483), (1266, 487)]\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5\n",
    "\n",
    "def find_optimal_targets(opponent_player, court_bounds):\n",
    "    distances = [(calculate_distance(opponent_player, corner), corner) for corner in court_bounds]\n",
    "    distances.sort(reverse=True, key=lambda x: x[0])\n",
    "    return [corner for _, corner in distances[:3]]\n",
    "\n",
    "def bounding_boxes_overlap(box1, box2):\n",
    "    \"\"\"Check if two bounding boxes overlap.\"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "    return not (x1_max < x2_min or x2_max < x1_min or y1_max < y2_min or y2_max < y1_min)\n",
    "\n",
    "def draw_arrows(frame, ball_position, targets):\n",
    "    for target in targets:\n",
    "        pt1 = (int(ball_position[0]), int(ball_position[1]))\n",
    "        pt2 = (int(target[0]), int(target[1]))\n",
    "        cv2.arrowedLine(frame, pt1, pt2, (0, 0, 255), 2, tipLength=0.2)  # Reduced tip size\n",
    "        cv2.circle(frame, pt2, 5, (0, 0, 255), -1)  # Small marker at target location\n",
    "\n",
    "# Video capture and writer setup\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_index = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Path to corresponding frame label file\n",
    "    label_file = os.path.join(frame_label_dir, f'frame_{frame_index:04d}.txt')\n",
    "\n",
    "    ball_position = None\n",
    "    racket_position = None\n",
    "    players = []\n",
    "\n",
    "    if os.path.exists(label_file):\n",
    "        # Read the label file\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            values = line.strip().split()\n",
    "            class_id = int(values[0])\n",
    "            x_center, y_center = float(values[1]) * width, float(values[2]) * height\n",
    "            box_width, box_height = float(values[3]) * width, float(values[4]) * height\n",
    "\n",
    "            # Calculate bounding box coordinates\n",
    "            x1 = int(x_center - box_width / 2)\n",
    "            y1 = int(y_center - box_height / 2)\n",
    "            x2 = int(x_center + box_width / 2)\n",
    "            y2 = int(y_center + box_height / 2)\n",
    "\n",
    "            # Store ball and racket positions\n",
    "            if class_id == 0:  # Ball\n",
    "                ball_position = (x_center, y_center)\n",
    "                ball_box = (x1, y1, x2, y2)\n",
    "            elif class_id == 2:  # Tennis racket\n",
    "                racket_position = (x_center, y_center)\n",
    "                racket_box = (x1, y1, x2, y2)\n",
    "            elif class_id == 1:  # Player\n",
    "                players.append((x_center, y_center))\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            color = class_colors.get(class_id, (255, 255, 255))  # Default to white if class_id is unknown\n",
    "            label = class_mapping.get(class_id, \"Unknown\")\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    # If ball and racket positions exist and overlap\n",
    "    if ball_position and racket_position and bounding_boxes_overlap(ball_box, racket_box):\n",
    "        # Find the opponent player farthest from the racket\n",
    "        if players:\n",
    "            opponent_player = max(players, key=lambda p: calculate_distance(racket_position, p))\n",
    "            # Predict target positions\n",
    "            targets = find_optimal_targets(opponent_player, opponent_court_bounds)\n",
    "            # Draw arrows\n",
    "            draw_arrows(frame, ball_position, targets)\n",
    "\n",
    "    # Write the frame to output video\n",
    "    out.write(frame)\n",
    "    frame_index += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video processing with predictions completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLOv8n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO(\"yolov8n.pt\")  # 사전 학습된 Nano 모델 사용\n",
    "\n",
    "# 데이터 훈련\n",
    "model.train(data=\"D:/data.yaml\", epochs=5, imgsz=640)  # data.yaml 파일 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to video and frame_label directory\n",
    "video_path = 'D:/Tennis_Video/Tennis_MP4_5.mp4'\n",
    "output_video_path = 'D:/Tennis_Video/Predict_path_Tennis.mp4'\n",
    "frame_label_dir = 'D:/Tennis_Video/frame_label'\n",
    "\n",
    "# Class mapping and colors\n",
    "class_mapping = {0: \"ball\", 1: \"player\", 2: \"tennis racket\", 3: \"referee\"}\n",
    "class_colors = {\n",
    "    0: (255, 0, 0),    # Blue for ball\n",
    "    1: (0, 255, 0),    # Green for player\n",
    "    2: (0, 0, 255),    # Red for tennis racket\n",
    "    3: (255, 255, 0)   # Yellow for referee\n",
    "}\n",
    "\n",
    "# Define opponent court bounds (top-left, top-right, bottom-left, bottom-right)\n",
    "opponent_court_bounds = [(733, 374), (1221, 372), (692, 483), (1266, 487)]\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)**0.5\n",
    "\n",
    "def find_optimal_targets(opponent_player, court_bounds):\n",
    "    distances = [(calculate_distance(opponent_player, corner), corner) for corner in court_bounds]\n",
    "    distances.sort(reverse=True, key=lambda x: x[0])\n",
    "    return [corner for _, corner in distances[:3]]\n",
    "\n",
    "def bounding_boxes_overlap(box1, box2):\n",
    "    \"\"\"Check if two bounding boxes overlap.\"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "    return not (x1_max < x2_min or x2_max < x1_min or y1_max < y2_min or y2_max < y1_min)\n",
    "\n",
    "def draw_arrows(frame, ball_position, targets):\n",
    "    for target in targets:\n",
    "        pt1 = (int(ball_position[0]), int(ball_position[1]))\n",
    "        pt2 = (int(target[0]), int(target[1]))\n",
    "        cv2.arrowedLine(frame, pt1, pt2, (0, 0, 255), 2, tipLength=0.2)  # Reduced tip size\n",
    "        cv2.circle(frame, pt2, 5, (0, 0, 255), -1)  # Small marker at target location\n",
    "\n",
    "# Video capture and writer setup\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_index = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Path to corresponding frame label file\n",
    "    label_file = os.path.join(frame_label_dir, f'frame_{frame_index:04d}.txt')\n",
    "\n",
    "    ball_position = None\n",
    "    racket_position = None\n",
    "    players = []\n",
    "\n",
    "    if os.path.exists(label_file):\n",
    "        # Read the label file\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            values = line.strip().split()\n",
    "            class_id = int(values[0])\n",
    "            x_center, y_center = float(values[1]) * width, float(values[2]) * height\n",
    "            box_width, box_height = float(values[3]) * width, float(values[4]) * height\n",
    "\n",
    "            # Calculate bounding box coordinates\n",
    "            x1 = int(x_center - box_width / 2)\n",
    "            y1 = int(y_center - box_height / 2)\n",
    "            x2 = int(x_center + box_width / 2)\n",
    "            y2 = int(y_center + box_height / 2)\n",
    "\n",
    "            # Store ball and racket positions\n",
    "            if class_id == 0:  # Ball\n",
    "                ball_position = (x_center, y_center)\n",
    "                ball_box = (x1, y1, x2, y2)\n",
    "            elif class_id == 2:  # Tennis racket\n",
    "                racket_position = (x_center, y_center)\n",
    "                racket_box = (x1, y1, x2, y2)\n",
    "            elif class_id == 1:  # Player\n",
    "                players.append((x_center, y_center))\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            color = class_colors.get(class_id, (255, 255, 255))  # Default to white if class_id is unknown\n",
    "            label = class_mapping.get(class_id, \"Unknown\")\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "    # If ball and racket positions exist and overlap\n",
    "    if ball_position and racket_position and bounding_boxes_overlap(ball_box, racket_box):\n",
    "        # Find the opponent player farthest from the racket\n",
    "        if players:\n",
    "            opponent_player = max(players, key=lambda p: calculate_distance(racket_position, p))\n",
    "            # Predict target positions\n",
    "            targets = find_optimal_targets(opponent_player, opponent_court_bounds)\n",
    "            # Draw arrows\n",
    "            draw_arrows(frame, ball_position, targets)\n",
    "\n",
    "    # Write the frame to output video\n",
    "    out.write(frame)\n",
    "    frame_index += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video processing with predictions completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths to data\n",
    "predicted_data_path = \"D:/Tennis_Video/predicted_data.csv\"\n",
    "ground_truth_path = \"D:/Tennis_Video/ground_truth_data.csv\"\n",
    "\n",
    "# Load data\n",
    "predicted_df = pd.read_csv(predicted_data_path)\n",
    "ground_truth_df = pd.read_csv(ground_truth_path)\n",
    "\n",
    "# IoU calculation function\n",
    "def calculate_iou(box1, box2):\n",
    "    x1_min, y1_min = box1[0] - box1[2] / 2, box1[1] - box1[3] / 2\n",
    "    x1_max, y1_max = box1[0] + box1[2] / 2, box1[1] + box1[3] / 2\n",
    "    x2_min, y2_min = box2[0] - box2[2] / 2, box2[1] - box2[3] / 2\n",
    "    x2_max, y2_max = box2[0] + box2[2] / 2, box2[1] + box2[3] / 2\n",
    "\n",
    "    inter_x_min, inter_y_min = max(x1_min, x2_min), max(y1_min, y2_min)\n",
    "    inter_x_max, inter_y_max = min(x1_max, x2_max), min(y1_max, y2_max)\n",
    "\n",
    "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "    union_area = (x1_max - x1_min) * (y1_max - y1_min) + (x2_max - x2_min) * (y2_max - y2_min) - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "tp, fp, fn = 0, 0, 0\n",
    "ious = []\n",
    "\n",
    "for frame in ground_truth_df[\"Frame\"].unique():\n",
    "    gt_frame = ground_truth_df[ground_truth_df[\"Frame\"] == frame]\n",
    "    pred_frame = predicted_df[predicted_df[\"Frame\"] == frame]\n",
    "\n",
    "    for _, gt_row in gt_frame.iterrows():\n",
    "        pred_row = pred_frame[pred_frame[\"Class\"] == gt_row[\"Class\"]]\n",
    "        if not pred_row.empty:\n",
    "            gt_box = [gt_row[\"X\"], gt_row[\"Y\"], gt_row[\"Width\"], gt_row[\"Height\"]]\n",
    "            pred_box = [pred_row.iloc[0][\"X\"], pred_row.iloc[0][\"Y\"], pred_row.iloc[0][\"Width\"], pred_row.iloc[0][\"Height\"]]\n",
    "            iou = calculate_iou(gt_box, pred_box)\n",
    "            if iou > 0.5:\n",
    "                tp += 1\n",
    "                ious.append(iou)\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "average_iou = np.mean(ious) if ious else 0\n",
    "# Results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Average IoU: {average_iou:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
